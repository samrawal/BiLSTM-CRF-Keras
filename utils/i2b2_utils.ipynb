{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk, os\n",
    "from word import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class i2b2Parser():    \n",
    "    filepath =  None\n",
    "    tokens = None\n",
    "    def __init__(self, filepath):\n",
    "        self.filepath = filepath\n",
    "    def parse_file(self):\n",
    "        with open(self.filepath, 'r') as f:\n",
    "            data = f.read().splitlines()\n",
    "        tokens = {}\n",
    "        for linenum, line in enumerate(data):\n",
    "            for tokennum, token in enumerate(line.split()):\n",
    "                token = {'text': token, 'token': tokennum, 'line': linenum + 1}\n",
    "                if linenum + 1 not in tokens: tokens[linenum + 1] = {}\n",
    "                tokens[linenum + 1][tokennum] = token\n",
    "        self.tokens = tokens\n",
    "    \n",
    "    def tag_gold_tokens(self, gold_file):\n",
    "        parsed_gold = {}\n",
    "        with open(gold_file, 'r') as f:\n",
    "            gold_data = f.read().splitlines()\n",
    "        for l in gold_data:\n",
    "            data_in_line = self.parse_gold_line(l)\n",
    "            for data in data_in_line:\n",
    "                if data['start_line'] != None:\n",
    "                    for line in range(data['start_line'], data['end_line']+1):\n",
    "                        if data['start_line'] == data['end_line']:\n",
    "                            for token in range(data['start_token'], data['end_token'] + 1):\n",
    "                                self.tokens[line][token]['gold_tag'] = data['concept']\n",
    "                                self.tokens[line][token]['gold_text'] = data['text']\n",
    "                        else: # if multi-line annotation\n",
    "                            if line == data['start_line']:\n",
    "                                for token in self.tokens[line]:\n",
    "                                    if token >= data['start_token']: \n",
    "                                        self.tokens[line][token]['gold_tag'] = data['concept']\n",
    "                                        self.tokens[line][token]['gold_text'] = data['text']\n",
    "                            elif line == data['end_line']:\n",
    "                                for token in self.tokens[line]:\n",
    "                                    if token <= data['end_token']: \n",
    "                                        self.tokens[line][token]['gold_tag'] = data['concept']\n",
    "                                        self.tokens[line][token]['gold_text'] = data['text']\n",
    "                            else:\n",
    "                                for token in self.tokens[line]:\n",
    "                                    self.tokens[line][token]['gold_tag'] = data['concept']\n",
    "                                    self.tokens[line][token]['gold_text'] = data['text']\n",
    "\n",
    "                                \n",
    "    def parse_gold_line(self, line):\n",
    "        bundle = []\n",
    "        chunks = line.split('||')\n",
    "        for chunk in chunks:\n",
    "            split_a = chunk.split('\\\" ')\n",
    "            concept = split_a[0].split('=')[0]\n",
    "            text = split_a[0].split('=')[1][1:]\n",
    "            \n",
    "            split_b = split_a[1].split() if len(split_a) > 1 else []\n",
    "            if len(split_b) == 0: # no start/end values here\n",
    "                start_line, start_token = None, None\n",
    "                end_line, end_token = None, None\n",
    "                bundle.append({\n",
    "                    'concept': concept,\n",
    "                    'text': text,\n",
    "                    'start_line': start_line,\n",
    "                    'start_token': start_token,\n",
    "                    'end_line': end_line,\n",
    "                    'end_token': end_token,\n",
    "                })\n",
    "\n",
    "            elif r',' not in split_b[1]:\n",
    "                [start_line, start_token] = split_b[0].split(':')\n",
    "                [end_line, end_token] = split_b[1].split(':')\n",
    "                bundle.append({\n",
    "                    'concept': concept,\n",
    "                    'text': text,\n",
    "                    'start_line': int(start_line),\n",
    "                    'start_token': int(start_token),\n",
    "                    'end_line': int(end_line),\n",
    "                    'end_token': int(end_token),\n",
    "                })\n",
    "            else:\n",
    "                groups = split_a[1].split(r',')\n",
    "                for group in groups:\n",
    "                    [start, end] = group.split()\n",
    "                    [start_line, start_token] = start.split(':')\n",
    "                    [end_line, end_token] = end.split(':')\n",
    "                    bundle.append({\n",
    "                        'concept': concept,\n",
    "                        'text': text,\n",
    "                        'start_line': int(start_line),\n",
    "                        'start_token': int(start_token),\n",
    "                        'end_line': int(end_line),\n",
    "                        'end_token': int(end_token),\n",
    "                    })\n",
    "        return bundle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.hycell": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def parse_all_gold_train():\n",
    "    count = 0\n",
    "    gold_files = ['11995', '133875', '150406', '180195', '182909','18563', '189350', '210958', '241468', '379569',]\n",
    "    data = {}\n",
    "    for filenum in gold_files:\n",
    "        colab_path = os.environ['colab']\n",
    "        data_path = colab_path + '/data/i2b2/2009 Medication Challenge/'\n",
    "        sample_file = data_path + '/training_sets_released_merged/{0}'.format(filenum)\n",
    "        sample_file_gold = data_path + '/training_ground_truth/training.ground.truth/{0}_gold.entries'.format(filenum)\n",
    "        parser = i2b2Parser(sample_file)\n",
    "        parser.parse_file()\n",
    "        parser.tag_gold_tokens(sample_file_gold)\n",
    "        tokens = parser.tokens\n",
    "        for line in tokens:\n",
    "            for token in tokens[line]: count += 1\n",
    "        data[filenum] = tokens\n",
    "    print('{0} tokens found across {1} files.'.format(count, len(gold_files)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "name": "i2b2_utils.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
